import os
import logging
import torch
from PIL import Image
from .base_pipeline import BasePipeline

logger = logging.getLogger(__name__)

class CPUPipeline(BasePipeline):
    """CPU è§†é¢‘ç”Ÿæˆç®¡é“"""

    def __init__(self, ckpt_dir: str, **model_args):  # ğŸ”¥ æ·»åŠ ckpt_dirå‚æ•°
        self.device_type = "cpu"
        super().__init__(ckpt_dir, **model_args)

    def _get_backend(self) -> str:
        return "gloo"

    def _load_model(self):
        logger.info(f"Rank {self.rank}: Loading model on CPU")
        # CPUæ¨¡å‹åŠ è½½é€»è¾‘
        # è¿™é‡Œæ·»åŠ ä½ çš„CPUæ¨¡å‹åŠ è½½ä»£ç 
        return None  # ä¸´æ—¶è¿”å›None

    def _generate_video_device_specific(self, request, img, progress_callback=None):
        logger.info(f"Rank {self.rank}: Generating video on CPU")
        # CPUè§†é¢‘ç”Ÿæˆé€»è¾‘
        # è¿™é‡Œæ·»åŠ ä½ çš„CPUæ¨ç†ä»£ç 
        return None  # ä¸´æ—¶è¿”å›None

    def _save_video(self, video_tensor, output_path: str):
        logger.info(f"Saving video to {output_path}")
        # åˆ›å»ºå ä½æ–‡ä»¶
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        with open(output_path, "wb") as f:
            f.write(b"FAKE_VIDEO_DATA")

    def _log_memory_usage(self):
        logger.info(f"Rank {self.rank} CPU Memory usage tracking not implemented")

    def _empty_cache(self):
        # CPUä¸éœ€è¦æ¸…ç©ºç¼“å­˜
        pass