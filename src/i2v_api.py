import os
import sys
import torch
import torch.distributed as dist
from datetime import datetime, timedelta

project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
sys.path.insert(0, project_root)

import logging
import uuid
import threading
import time
from typing import List
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
import uvicorn

from schemas import VideoSubmitRequest, VideoSubmitResponse, VideoStatusResponse, TaskStatus
from pipelines.pipeline_factory import create_pipeline
from utils.device_detector import detect_device

logging.basicConfig(level=logging.INFO, format="%(asctime)s %(levelname)s %(message)s")
logger = logging.getLogger(__name__)

# å…¨å±€å˜é‡
task_queue = []
status_dict = {}
cancelled_tasks = set()
pipeline = None

def init_distributed():
    """åˆå§‹åŒ–åˆ†å¸ƒå¼ç¯å¢ƒ"""
    try:
        import torch_npu
        npu_available = torch_npu.npu.is_available()
    except ImportError:
        npu_available = False
    
    # è·å–åˆ†å¸ƒå¼ä¿¡æ¯
    rank = int(os.environ.get("RANK", 0))
    local_rank = int(os.environ.get("LOCAL_RANK", 0))
    world_size = int(os.environ.get("WORLD_SIZE", 1))
    
    logger.info(f"Initializing rank {rank}/{world_size}, local_rank {local_rank}")
    
    if world_size > 1:
        # ğŸ”¥ å…ˆè®¾ç½®è®¾å¤‡å†åˆå§‹åŒ–åˆ†å¸ƒå¼
        if npu_available:
            import torch_npu
            torch_npu.npu.set_device(local_rank)  # ğŸ”¥ ä½¿ç”¨torch_npu.npu.set_device
            logger.info(f"Rank {rank}: Set NPU device {local_rank}")
        elif torch.cuda.is_available():
            torch.cuda.set_device(local_rank)
            logger.info(f"Rank {rank}: Set CUDA device {local_rank}")
        
        # ğŸ”¥ ä½¿ç”¨æ­£ç¡®çš„åˆ†å¸ƒå¼åˆå§‹åŒ–
        backend = "hccl" if npu_available else "nccl" if torch.cuda.is_available() else "gloo"
        
        try:
            if not dist.is_initialized():
                dist.init_process_group(
                    backend=backend,
                    timeout=timedelta(seconds=300),  # ğŸ”¥ æ·»åŠ è¶…æ—¶
                    init_method='env://'  # ğŸ”¥ æ˜ç¡®æŒ‡å®š
                )
                logger.info(f"Rank {rank}: Distributed initialized with {backend}")
            else:
                logger.info(f"Rank {rank}: Distributed already initialized")
        except Exception as e:
            logger.error(f"Rank {rank}: Failed to initialize distributed: {e}")
            raise
    else:
        logger.info(f"Rank {rank}: Single device mode")
    
    return rank, local_rank, world_size

def create_app():
    """åˆ›å»ºFastAPIåº”ç”¨"""
    app = FastAPI(title="Wan2.1 I2V Multi-Device API Server")
    app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"])
    
    os.makedirs("generated_videos", exist_ok=True)
    app.mount("/videos", StaticFiles(directory="generated_videos"), name="videos")

    @app.post("/submit", response_model=VideoSubmitResponse)
    async def submit(request: VideoSubmitRequest):
        task_id = f"req_{uuid.uuid4().hex[:16]}"
        status_dict[task_id] = {
            "status": TaskStatus.PENDING, 
            "result_url": "", 
            "error": "",
            "created_at": datetime.now().isoformat(),
            "progress": 0
        }
        task_queue.append((task_id, request))
        logger.info(f"Task submitted: {task_id}")
        return VideoSubmitResponse(requestId=task_id, status=TaskStatus.PENDING, message="ä»»åŠ¡å·²æäº¤", estimated_time=30)

    @app.post("/batch_submit", response_model=List[VideoSubmitResponse])
    async def batch_submit(requests: List[VideoSubmitRequest]):
        responses = []
        for req in requests:
            task_id = f"req_{uuid.uuid4().hex[:16]}"
            status_dict[task_id] = {
                "status": TaskStatus.PENDING, 
                "result_url": "", 
                "error": "",
                "created_at": datetime.now().isoformat(),
                "progress": 0
            }
            task_queue.append((task_id, req))
            responses.append(VideoSubmitResponse(requestId=task_id, status=TaskStatus.PENDING, message="ä»»åŠ¡å·²æäº¤", estimated_time=30))
        return responses

    # ğŸ”¥ æ–°å¢ï¼šå–æ¶ˆä»»åŠ¡
    @app.post("/cancel/{task_id}")
    async def cancel_task(task_id: str):
        if task_id not in status_dict:
            raise HTTPException(status_code=404, detail="Task not found")
        
        current_status = status_dict[task_id]["status"]
        if current_status in [TaskStatus.SUCCEED, TaskStatus.FAILED, TaskStatus.CANCELLED]:
            raise HTTPException(status_code=400, detail=f"Task already {current_status.value}")
        
        cancelled_tasks.add(task_id)
        status_dict[task_id]["status"] = TaskStatus.CANCELLED
        status_dict[task_id]["updated_at"] = datetime.now().isoformat()
        
        # ä»é˜Ÿåˆ—ä¸­ç§»é™¤
        global task_queue
        task_queue = [(tid, req) for tid, req in task_queue if tid != task_id]
        
        logger.info(f"Task {task_id} cancelled")
        return {"message": f"Task {task_id} cancelled successfully"}

    @app.post("/cancel_all")
    async def cancel_all():
        cancelled_count = 0
        for task_id, task_info in status_dict.items():
            if task_info["status"] in [TaskStatus.PENDING, TaskStatus.RUNNING]:
                cancelled_tasks.add(task_id)
                status_dict[task_id]["status"] = TaskStatus.CANCELLED
                status_dict[task_id]["updated_at"] = datetime.now().isoformat()
                cancelled_count += 1
        
        global task_queue
        task_queue = []
        
        logger.info(f"Cancelled {cancelled_count} tasks")
        return {"message": f"Cancelled {cancelled_count} tasks"}

    @app.get("/status/{task_id}", response_model=VideoStatusResponse)
    async def status(task_id: str):
        s = status_dict.get(task_id)
        if not s:
            raise HTTPException(status_code=404, detail="Task not found")

        # ğŸ”¥ æ–°å¢ï¼šåŠ¨æ€æ¶ˆæ¯
        message = "ä»»åŠ¡å¤„ç†ä¸­"
        if s.get("status") == TaskStatus.RUNNING:
            stage = s.get("current_stage", "å¤„ç†ä¸­")
            progress = s.get("progress", 0)
            message = f"{stage} ({progress:.1f}%)"
        elif s.get("status") == TaskStatus.FAILED:
            message = s.get("error", "ç”Ÿæˆå¤±è´¥")
        elif s.get("status") == TaskStatus.SUCCEED:
            message = "ç”Ÿæˆå®Œæˆ"
        elif s.get("status") == TaskStatus.CANCELLED:
            message = "ä»»åŠ¡å·²å–æ¶ˆ"

        return VideoStatusResponse(
            requestId=task_id,
            status=s.get("status", TaskStatus.PENDING),
            progress=s.get("progress", 0),
            message=message,  # ğŸ”¥ ä¿®æ”¹ï¼šä½¿ç”¨åŠ¨æ€æ¶ˆæ¯
            created_at=s.get("created_at", ""),
            updated_at=s.get("updated_at", ""),
            results=s.get("results"),
            reason=s.get("reason"),
            elapsed_time=s.get("elapsed_time"),
            current_stage=s.get("current_stage"),  # ğŸ”¥ æ–°å¢
        )

    @app.get("/health")
    async def health():
        dtype, dcount, backend = detect_device()
        return {
            "device_type": dtype, 
            "device_count": dcount, 
            "backend": backend, 
            "queue_size": len(task_queue), 
            "total_tasks": len(status_dict),
            "cancelled_tasks": len(cancelled_tasks)
        }
    
    @app.get("/monitor")
    async def monitor():
        """ç®€å•çš„ä»»åŠ¡ç›‘æ§"""
        running = [{"id": k, "progress": v.get("progress", 0), "stage": v.get("current_stage", "")} 
                   for k, v in status_dict.items() if v.get("status") == TaskStatus.RUNNING]

        return {
            "queue_size": len(task_queue),
            "running_tasks": running,
            "total_tasks": len(status_dict)
        }

    return app

def process_tasks():
    """å¤„ç†ä»»åŠ¡é˜Ÿåˆ—"""
    while task_queue:
        task_id, request = task_queue.pop(0)
        
        # æ£€æŸ¥æ˜¯å¦è¢«å–æ¶ˆ
        if task_id in cancelled_tasks:
            logger.info(f"Task {task_id} was cancelled, skipping")
            continue
            
        try:
            logger.info(f"ğŸš€ Processing task: {task_id}")
            status_dict[task_id]["status"] = TaskStatus.RUNNING
            status_dict[task_id]["updated_at"] = datetime.now().isoformat()
            status_dict[task_id]["start_time"] = datetime.now()  # ğŸ”¥ æ–°å¢ï¼šè®°å½•å¼€å§‹æ—¶é—´
            
            # ğŸ”¥ ä¿®æ”¹ï¼šå¢å¼ºçš„è¿›åº¦å›è°ƒ
            def progress_callback(progress, stage="Processing"):
                if task_id in cancelled_tasks:
                    raise Exception("Task was cancelled")
                status_dict[task_id]["progress"] = progress
                status_dict[task_id]["current_stage"] = stage  # ğŸ”¥ æ–°å¢ï¼šå½“å‰é˜¶æ®µ
                
                # ğŸ”¥ æ–°å¢ï¼šè¯¦ç»†æ—¥å¿—
                elapsed = datetime.now() - status_dict[task_id]["start_time"]
                logger.info(f"ğŸ“Š Task {task_id}: {stage} ({progress:.1f}%) - Elapsed: {elapsed}")
                return progress
            
            result = pipeline.generate_video(request, task_id, progress_callback=progress_callback)
            
            # æœ€åæ£€æŸ¥ä¸€æ¬¡æ˜¯å¦è¢«å–æ¶ˆ
            if task_id in cancelled_tasks:
                logger.info(f"Task {task_id} was cancelled during processing")
                continue
            
            # ğŸ”¥ æ–°å¢ï¼šè®¡ç®—æ€»è€—æ—¶
            total_time = datetime.now() - status_dict[task_id]["start_time"]
            
            status_dict[task_id]["status"] = TaskStatus.SUCCEED
            status_dict[task_id]["result_url"] = result
            status_dict[task_id]["updated_at"] = datetime.now().isoformat()
            status_dict[task_id]["elapsed_time"] = str(total_time)  # ğŸ”¥ æ–°å¢
            logger.info(f"âœ… Task {task_id} completed successfully in {total_time}")
            
        except Exception as e:
            # ğŸ”¥ æ–°å¢ï¼šå¼‚å¸¸æ—¶ä¹Ÿè®°å½•è€—æ—¶
            if "start_time" in status_dict[task_id]:
                total_time = datetime.now() - status_dict[task_id]["start_time"]
                status_dict[task_id]["elapsed_time"] = str(total_time)
            
            if task_id in cancelled_tasks:
                logger.info(f"âŒ Task {task_id} cancelled during processing")
            else:
                status_dict[task_id]["status"] = TaskStatus.FAILED
                status_dict[task_id]["error"] = str(e)
                status_dict[task_id]["updated_at"] = datetime.now().isoformat()
                logger.error(f"ğŸ’¥ Task {task_id} failed: {e}")

def main():
    global pipeline
    
    # åˆå§‹åŒ–åˆ†å¸ƒå¼
    rank, local_rank, world_size = init_distributed()
    
    # åˆ›å»ºpipeline
    pipeline = create_pipeline()
    logger.info(f"Rank {rank}: Pipeline created successfully")
    
    # åªæœ‰rank 0è¿è¡ŒAPIæœåŠ¡å™¨
    if rank == 0:
        app = create_app()
        
        # å¯åŠ¨åå°ä»»åŠ¡å¤„ç†çº¿ç¨‹
        def task_worker():
            while True:
                process_tasks()
                time.sleep(0.1)
        
        threading.Thread(target=task_worker, daemon=True).start()
        
        # å¯åŠ¨APIæœåŠ¡å™¨
        logger.info("Starting API server on rank 0...")
        uvicorn.run(app, host="0.0.0.0", port=8088)
    else:
        # å…¶ä»–rankç­‰å¾…å¹¶å‚ä¸åˆ†å¸ƒå¼è®¡ç®—
        logger.info(f"Rank {rank}: Waiting for distributed tasks...")
        while True:
            time.sleep(1)

if __name__ == "__main__":
    main()