import os
import sys
import torch
import torch.distributed as dist
from datetime import datetime, timedelta

project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
sys.path.insert(0, project_root)

import logging
import uuid
import threading
import time
from typing import List
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
import uvicorn

from schemas import VideoSubmitRequest, VideoSubmitResponse, VideoStatusResponse, TaskStatus
from pipelines.pipeline_factory import create_pipeline
from utils.device_detector import detect_device

logging.basicConfig(level=logging.INFO, format="%(asctime)s %(levelname)s %(message)s")
logger = logging.getLogger(__name__)

# å…¨å±€å˜é‡
task_queue = []
status_dict = {}
cancelled_tasks = set()
pipeline = None

def init_distributed():
    """åˆå§‹åŒ–åˆ†å¸ƒå¼ç¯å¢ƒ"""
    try:
        import torch_npu
        npu_available = torch_npu.npu.is_available()
    except ImportError:
        npu_available = False
    
    # è·å–åˆ†å¸ƒå¼ä¿¡æ¯
    rank = int(os.environ.get("RANK", 0))
    local_rank = int(os.environ.get("LOCAL_RANK", 0))
    world_size = int(os.environ.get("WORLD_SIZE", 1))
    
    logger.info(f"Initializing rank {rank}/{world_size}, local_rank {local_rank}")
    
    if world_size > 1:
        # ğŸ”¥ å…ˆè®¾ç½®è®¾å¤‡å†åˆå§‹åŒ–åˆ†å¸ƒå¼
        if npu_available:
            import torch_npu
            torch_npu.npu.set_device(local_rank)  # ğŸ”¥ ä½¿ç”¨torch_npu.npu.set_device
            logger.info(f"Rank {rank}: Set NPU device {local_rank}")
        elif torch.cuda.is_available():
            torch.cuda.set_device(local_rank)
            logger.info(f"Rank {rank}: Set CUDA device {local_rank}")
        
        # ğŸ”¥ ä½¿ç”¨æ­£ç¡®çš„åˆ†å¸ƒå¼åˆå§‹åŒ–
        backend = "hccl" if npu_available else "nccl" if torch.cuda.is_available() else "gloo"
        
        try:
            if not dist.is_initialized():
                dist.init_process_group(
                    backend=backend,
                    timeout=timedelta(seconds=300),  # ğŸ”¥ æ·»åŠ è¶…æ—¶
                    init_method='env://'  # ğŸ”¥ æ˜ç¡®æŒ‡å®š
                )
                logger.info(f"Rank {rank}: Distributed initialized with {backend}")
            else:
                logger.info(f"Rank {rank}: Distributed already initialized")
        except Exception as e:
            logger.error(f"Rank {rank}: Failed to initialize distributed: {e}")
            raise
    else:
        logger.info(f"Rank {rank}: Single device mode")
    
    return rank, local_rank, world_size

def create_app():
    """åˆ›å»ºFastAPIåº”ç”¨"""
    app = FastAPI(title="Wan2.1 I2V Multi-Device API Server")
    app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"])
    
    os.makedirs("generated_videos", exist_ok=True)
    app.mount("/videos", StaticFiles(directory="generated_videos"), name="videos")

    @app.post("/submit", response_model=VideoSubmitResponse)
    async def submit(request: VideoSubmitRequest):
        task_id = f"req_{uuid.uuid4().hex[:16]}"
        status_dict[task_id] = {
            "status": TaskStatus.PENDING, 
            "result_url": "", 
            "error": "",
            "created_at": datetime.now().isoformat(),
            "progress": 0
        }
        task_queue.append((task_id, request))
        logger.info(f"Task submitted: {task_id}")
        return VideoSubmitResponse(requestId=task_id, status=TaskStatus.PENDING, message="ä»»åŠ¡å·²æäº¤", estimated_time=30)

    @app.post("/batch_submit", response_model=List[VideoSubmitResponse])
    async def batch_submit(requests: List[VideoSubmitRequest]):
        responses = []
        for req in requests:
            task_id = f"req_{uuid.uuid4().hex[:16]}"
            status_dict[task_id] = {
                "status": TaskStatus.PENDING, 
                "result_url": "", 
                "error": "",
                "created_at": datetime.now().isoformat(),
                "progress": 0
            }
            task_queue.append((task_id, req))
            responses.append(VideoSubmitResponse(requestId=task_id, status=TaskStatus.PENDING, message="ä»»åŠ¡å·²æäº¤", estimated_time=30))
        return responses

    # ğŸ”¥ æ–°å¢ï¼šå–æ¶ˆä»»åŠ¡
    @app.post("/cancel/{task_id}")
    async def cancel_task(task_id: str):
        if task_id not in status_dict:
            raise HTTPException(status_code=404, detail="Task not found")
        
        current_status = status_dict[task_id]["status"]
        if current_status in [TaskStatus.SUCCEED, TaskStatus.FAILED, TaskStatus.CANCELLED]:
            raise HTTPException(status_code=400, detail=f"Task already {current_status.value}")
        
        cancelled_tasks.add(task_id)
        status_dict[task_id]["status"] = TaskStatus.CANCELLED
        status_dict[task_id]["updated_at"] = datetime.now().isoformat()
        
        # ä»é˜Ÿåˆ—ä¸­ç§»é™¤
        global task_queue
        task_queue = [(tid, req) for tid, req in task_queue if tid != task_id]
        
        logger.info(f"Task {task_id} cancelled")
        return {"message": f"Task {task_id} cancelled successfully"}

    @app.post("/cancel_all")
    async def cancel_all():
        cancelled_count = 0
        for task_id, task_info in status_dict.items():
            if task_info["status"] in [TaskStatus.PENDING, TaskStatus.RUNNING]:
                cancelled_tasks.add(task_id)
                status_dict[task_id]["status"] = TaskStatus.CANCELLED
                status_dict[task_id]["updated_at"] = datetime.now().isoformat()
                cancelled_count += 1
        
        global task_queue
        task_queue = []
        
        logger.info(f"Cancelled {cancelled_count} tasks")
        return {"message": f"Cancelled {cancelled_count} tasks"}

    @app.get("/status/{task_id}", response_model=VideoStatusResponse)
    async def status(task_id: str):
        s = status_dict.get(task_id)
        if not s:
            raise HTTPException(status_code=404, detail="Task not found")

        # ğŸ”¥ æ–°å¢ï¼šåŠ¨æ€æ¶ˆæ¯
        message = "ä»»åŠ¡å¤„ç†ä¸­"
        if s.get("status") == TaskStatus.RUNNING:
            stage = s.get("current_stage", "å¤„ç†ä¸­")
            progress = s.get("progress", 0)
            message = f"{stage} ({progress:.1f}%)"
        elif s.get("status") == TaskStatus.FAILED:
            message = s.get("error", "ç”Ÿæˆå¤±è´¥")
        elif s.get("status") == TaskStatus.SUCCEED:
            message = "ç”Ÿæˆå®Œæˆ"
        elif s.get("status") == TaskStatus.CANCELLED:
            message = "ä»»åŠ¡å·²å–æ¶ˆ"

        return VideoStatusResponse(
            requestId=task_id,
            status=s.get("status", TaskStatus.PENDING),
            progress=s.get("progress", 0),
            message=message,  # ğŸ”¥ ä¿®æ”¹ï¼šä½¿ç”¨åŠ¨æ€æ¶ˆæ¯
            created_at=s.get("created_at", ""),
            updated_at=s.get("updated_at", ""),
            results=s.get("results"),
            reason=s.get("reason"),
            elapsed_time=s.get("elapsed_time"),
            current_stage=s.get("current_stage"),  # ğŸ”¥ æ–°å¢
        )

    @app.get("/health")
    async def health():
        dtype, dcount, backend = detect_device()
        return {
            "device_type": dtype, 
            "device_count": dcount, 
            "backend": backend, 
            "queue_size": len(task_queue), 
            "total_tasks": len(status_dict),
            "cancelled_tasks": len(cancelled_tasks)
        }
    
    @app.get("/monitor")
    async def monitor():
        """ç®€å•çš„ä»»åŠ¡ç›‘æ§"""
        running = [{"id": k, "progress": v.get("progress", 0), "stage": v.get("current_stage", "")} 
                   for k, v in status_dict.items() if v.get("status") == TaskStatus.RUNNING]

        return {
            "queue_size": len(task_queue),
            "running_tasks": running,
            "total_tasks": len(status_dict)
        }

    return app

def process_tasks():
    """å¤„ç†ä»»åŠ¡é˜Ÿåˆ—"""
    while task_queue:
        task_id, request = task_queue.pop(0)
        
        if task_id in cancelled_tasks:
            logger.info(f"Task {task_id} was cancelled, skipping")
            continue
            
        try:
            logger.info(f"ğŸš€ Processing task: {task_id}")
            status_dict[task_id]["status"] = TaskStatus.RUNNING
            status_dict[task_id]["updated_at"] = datetime.now().isoformat()
            status_dict[task_id]["start_time"] = datetime.now()
            
            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šå¹¿æ’­ä»»åŠ¡ç»™æ‰€æœ‰rank
            world_size = int(os.environ.get("WORLD_SIZE", 1))
            if world_size > 1:
                import torch.distributed as dist
                if dist.is_initialized():
                    task_data = [{'request': request, 'task_id': task_id}]
                    dist.broadcast_object_list(task_data, src=0)
                    logger.info(f"Task {task_id} broadcasted to all {world_size} ranks")
            
            def progress_callback(progress, stage="Processing"):
                if task_id in cancelled_tasks:
                    raise Exception("Task was cancelled")
                status_dict[task_id]["progress"] = progress
                status_dict[task_id]["current_stage"] = stage
                
                elapsed = datetime.now() - status_dict[task_id]["start_time"]
                logger.info(f"ğŸ“Š Task {task_id}: {stage} ({progress:.1f}%) - Elapsed: {elapsed}")
                return progress
            
            # ğŸ”¥ ç°åœ¨æ‰€æœ‰rankéƒ½ä¼šå‚ä¸è¿™ä¸ªè°ƒç”¨
            result = pipeline.generate_video(request, task_id, progress_callback=progress_callback)
            
            # ğŸ”¥ æ·»åŠ ï¼šä»»åŠ¡å®Œæˆåç­‰å¾…æ‰€æœ‰rankåŒæ­¥
            if world_size > 1:
                import torch.distributed as dist
                if dist.is_initialized():
                    try:
                        dist.barrier(timeout=timedelta(seconds=30))
                        logger.info(f"Task {task_id}: All ranks synchronized after completion")
                    except Exception as e:
                        logger.warning(f"Task {task_id}: Post-completion barrier failed: {e}")
             
            # æœ€åæ£€æŸ¥ä¸€æ¬¡æ˜¯å¦è¢«å–æ¶ˆ
            if task_id in cancelled_tasks:
                logger.info(f"Task {task_id} was cancelled during processing")
                continue
            
            # ğŸ”¥ æ–°å¢ï¼šè®¡ç®—æ€»è€—æ—¶
            total_time = datetime.now() - status_dict[task_id]["start_time"]
            
            status_dict[task_id]["status"] = TaskStatus.SUCCEED
            status_dict[task_id]["result_url"] = result
            status_dict[task_id]["updated_at"] = datetime.now().isoformat()
            status_dict[task_id]["elapsed_time"] = str(total_time)  # ğŸ”¥ æ–°å¢
            logger.info(f"âœ… Task {task_id} completed successfully in {total_time}")
            
        except Exception as e:
            # ğŸ”¥ æ–°å¢ï¼šå¼‚å¸¸æ—¶ä¹Ÿè®°å½•è€—æ—¶
            if "start_time" in status_dict[task_id]:
                total_time = datetime.now() - status_dict[task_id]["start_time"]
                status_dict[task_id]["elapsed_time"] = str(total_time)
            
            if task_id in cancelled_tasks:
                logger.info(f"âŒ Task {task_id} cancelled during processing")
            else:
                status_dict[task_id]["status"] = TaskStatus.FAILED
                status_dict[task_id]["error"] = str(e)
                status_dict[task_id]["updated_at"] = datetime.now().isoformat()
                logger.error(f"ğŸ’¥ Task {task_id} failed: {e}")

def main():
    global pipeline
    rank, local_rank, world_size = init_distributed()  # ğŸ”¥ ä¿®å¤ï¼šè°ƒç”¨init_distributed
    
    logger.info(f"Rank {rank}: Starting I2V API service (world_size={world_size})")
    
    # ğŸ”¥ æ‰€æœ‰rankéƒ½åˆ›å»ºpipelineï¼ˆå¯¹é½æœ¬åœ°generate.pyï¼‰
    pipeline = create_pipeline()
    logger.info(f"Rank {rank}: Pipeline created successfully")
    
    if rank == 0:
        # ğŸ”¥ ä¿®å¤ï¼šåˆ›å»ºappå¯¹è±¡
        app = create_app()
        
        # rank 0è¿è¡ŒFastAPIæœåŠ¡ + å·¥ä½œå¾ªç¯
        logger.info("Rank 0: Starting FastAPI server...")
        import threading
        
        # ğŸ”¥ åœ¨åå°çº¿ç¨‹å¯åŠ¨ä»»åŠ¡å¤„ç†å¾ªç¯
        task_thread = threading.Thread(target=task_processing_loop, daemon=True)
        task_thread.start()
        
        # ğŸ”¥ åœ¨åå°çº¿ç¨‹å¯åŠ¨å·¥ä½œå¾ªç¯
        worker_thread = threading.Thread(target=distributed_worker_loop, daemon=True)
        worker_thread.start()
        
        uvicorn.run(app, host="0.0.0.0", port=8088, log_level="info")
    else:
        # ğŸ”¥ å…¶ä»–rankè¿è¡Œå·¥ä½œå¾ªç¯
        logger.info(f"Rank {rank}: Starting distributed worker...")
        distributed_worker_loop()

def task_processing_loop():
    """ä»»åŠ¡å¤„ç†å¾ªç¯ï¼ˆåªåœ¨rank 0è¿è¡Œï¼‰"""
    logger.info("Task processing loop started")
    while True:
        try:
            process_tasks()  # å¤„ç†ä»»åŠ¡é˜Ÿåˆ—
            time.sleep(0.1)  # é˜²æ­¢CPUå ç”¨è¿‡é«˜
        except KeyboardInterrupt:
            logger.info("Task processing loop interrupted")
            break
        except Exception as e:
            logger.error(f"Task processing error: {e}")
            time.sleep(1)

def distributed_worker_loop():
    """åˆ†å¸ƒå¼å·¥ä½œå¾ªç¯ - æ‰€æœ‰rankéƒ½å‚ä¸"""
    rank = int(os.environ.get("RANK", 0))
    
    logger.info(f"Rank {rank}: Worker ready for distributed tasks")
    
    if rank == 0:
        logger.info("Rank 0: Main worker loop handled by task processing")
        return
    else:
        logger.info(f"Rank {rank}: Waiting for distributed tasks...")
        
        import torch.distributed as dist
        while True:
            try:
                if dist.is_initialized():
                    # ğŸ”¥ å…³é”®ï¼šç­‰å¾…rank 0çš„ä»»åŠ¡å¹¿æ’­
                    task_data = [None]
                    dist.broadcast_object_list(task_data, src=0)
                    
                    if task_data[0] is not None:
                        if task_data[0] == "SHUTDOWN":  # ğŸ”¥ æ·»åŠ ï¼šå…³é—­ä¿¡å·
                            logger.info(f"Rank {rank}: Received shutdown signal")
                            break
                            
                        request, task_id = task_data[0]['request'], task_data[0]['task_id']
                        logger.info(f"Rank {rank}: Received task {task_id}")
                        
                        try:
                            # ğŸ”¥ å…³é”®ï¼šå…¶ä»–rankä¹Ÿè°ƒç”¨generate_video
                            pipeline.generate_video(request, task_id)
                            logger.info(f"Rank {rank}: Task {task_id} completed successfully")
                            
                        except Exception as e:
                            logger.error(f"Rank {rank}: Task {task_id} failed: {e}")
                            
                        # ğŸ”¥ æ·»åŠ ï¼šä»»åŠ¡å®Œæˆåçš„åŒæ­¥
                        try:
                            dist.barrier(timeout=timedelta(seconds=30))
                            logger.info(f"Rank {rank}: Post-task barrier completed")
                        except Exception as e:
                            logger.warning(f"Rank {rank}: Post-task barrier failed: {e}")
                            
                else:
                    time.sleep(0.1)
                    
            except KeyboardInterrupt:
                logger.info(f"Rank {rank}: Received interrupt")
                break
            except Exception as e:
                logger.error(f"Rank {rank}: Worker error: {e}")
                time.sleep(0.1)
                
        # ğŸ”¥ æ·»åŠ ï¼šé€€å‡ºæ—¶çš„æ¸…ç†
        logger.info(f"Rank {rank}: Worker loop exiting, cleaning up...")
        try:
            if dist.is_initialized():
                dist.barrier(timeout=timedelta(seconds=10))
                logger.info(f"Rank {rank}: Final cleanup barrier completed")
        except Exception as e:
            logger.warning(f"Rank {rank}: Final cleanup failed: {e}")

if __name__ == "__main__":
    main()